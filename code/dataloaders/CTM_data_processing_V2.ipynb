{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/181 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg dataset:\n",
      "845929 :\n",
      "> <ipython-input-1-eebeb4f94cf2>(105)covert_h5()\n",
      "-> ratio = (np.array(newspacing)/np.array(oldspacing)).tolist()\n",
      "(Pdb) image.shape\n",
      "(512, 512, 92)\n",
      "(Pdb) label.shape\n",
      "(512, 512, 92)\n",
      "(Pdb) n\n",
      "> <ipython-input-1-eebeb4f94cf2>(106)covert_h5()\n",
      "-> image = transform.rescale(image,ratio,order=1,anti_aliasing=True,preserve_range=True,multichannel=False)\n",
      "(Pdb) n\n",
      "> <ipython-input-1-eebeb4f94cf2>(107)covert_h5()\n",
      "-> label = np.round(transform.rescale(label,ratio,order=0,anti_aliasing=True,preserve_range=True,multichannel=False)).astype(int)\n",
      "(Pdb) n\n",
      "> <ipython-input-1-eebeb4f94cf2>(113)covert_h5()\n",
      "-> image = (image - np.mean(image)) / np.std(image)\n",
      "(Pdb) index_cut=np.where(label==1)\n",
      "(Pdb) index_cut[0].max(),index_cut[0].min()\n",
      "(327, 0)\n",
      "(Pdb) index_cut[1].max(),index_cut[1].min()\n",
      "(324, 81)\n",
      "(Pdb) index_cut[2].max(),index_cut[2].min()\n",
      "(91, 0)\n",
      "(Pdb) help(transform.rescale)\n",
      "*** No help for '(transform.rescale)'\n",
      "(Pdb) ratio\n",
      "[0.641025641025641, 0.641025641025641, 1.0]\n",
      "(Pdb) index_cut\n",
      "(array([  0,   0,   0, ..., 327, 327, 327]), array([166, 168, 171, ..., 172, 172, 173]), array([31, 29, 28, ..., 67, 69, 66]))\n",
      "(Pdb) sample_name\n",
      "'845929'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import nrrd\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataset_split import remove_files\n",
    "import SimpleITK as sitk\n",
    "from skimage import transform\n",
    "\n",
    "output_size =[128, 128, 64]\n",
    "\n",
    "def resample_image3D(\n",
    "    image3D,\n",
    "    newspacing=[0.3,0.3,3],\n",
    "    newsize=None,\n",
    "    method='Linear',):\n",
    "    \"\"\"做插值\"\"\"\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    if method is 'Linear':\n",
    "        resample.SetInterpolator(sitk.sitkLinear)\n",
    "    elif method is 'Nearest':\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resample.SetOutputDirection(image3D.GetDirection())\n",
    "    resample.SetOutputOrigin(image3D.GetOrigin())\n",
    "    resample.SetOutputSpacing(newspacing)\n",
    "\n",
    "    if not newsize:\n",
    "        newsize = np.round(np.array(image3D.GetSize())*np.abs(image3D.GetSpacing())/np.array(newspacing)).astype('int').tolist()\n",
    "\n",
    "    resample.SetSize(newsize)\n",
    "    # resample.SetDefaultPixelValue(0)\n",
    "\n",
    "    newimage = resample.Execute(image3D)\n",
    "    return newimage\n",
    "\n",
    "# 数组替换元素\n",
    "def array_replace(array,olds,news):\n",
    "    #olds:list of old value\n",
    "    #news:list of new value\n",
    "    olds = np.array(olds)\n",
    "    news = np.array(news)\n",
    "    offset = olds.max()*10\n",
    "    tmps = olds+offset\n",
    "    for old,tmp in zip(olds,tmps):\n",
    "        array[array==old] = tmp\n",
    "    for tmp,new in zip(tmps,news):\n",
    "        array[array==tmp] = new\n",
    "    return array\n",
    "\n",
    "def covert_h5(glob_str, old_replaced, new_replaced):\n",
    "    \"\"\"\n",
    "    备注：不要骨头，骨头合并到背景类别中\n",
    "    \"\"\"\n",
    "    listt = glob(glob_str)\n",
    "    error_samples = []\n",
    "    error_samples_origin = []\n",
    "    stats = pd.DataFrame(columns=['sample_name',\n",
    "                                  'mean_whole', \n",
    "                                  'mean_bg', \n",
    "                                  'mean_dura', \n",
    "                                  'mean_SC', \n",
    "                                  'std_whole',\n",
    "                                  'std_bg',\n",
    "                                  'std_dura',\n",
    "                                  'std_SC',\n",
    "                                  'old_space0','old_space1','old_space2',\n",
    "                                  'new_space0','new_space1','new_space2',\n",
    "                                 ])\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "\n",
    "        image = sitk.ReadImage(item)\n",
    "        label = sitk.ReadImage(item.replace(old_replaced, 'Segmentation-label.nrrd'))\n",
    "        seg = sitk.ReadImage(item.replace(old_replaced, 'Segmentation.seg.nrrd'))\n",
    "        \n",
    "        oldspacing = np.abs(image.GetSpacing())\n",
    "        newspacing = [0.3, 0.3, 3.0]\n",
    "#         offset = [int(k) for k in seg.GetMetaData('Segmentation_ReferenceImageExtentOffset').split()]\n",
    "#         offset = np.round(np.array(offset)*np.array(oldspacing)/np.array(newspacing)).astype(int).tolist()\n",
    "        label_name = [\n",
    "            seg.GetMetaData('Segment0_Name'),\n",
    "            seg.GetMetaData('Segment1_Name'),\n",
    "            seg.GetMetaData('Segment2_Name') \n",
    "            ]#人工标注的类别顺序\n",
    "        \n",
    "        # resample\n",
    "#         image = resample_image3D(image,newspacing,method='Linear')\n",
    "#         label = resample_image3D(label,newspacing,method='Nearest')##,newsize=image.GetSize()\n",
    "#         seg = resample_image3D(seg,newspacing)\n",
    "        \n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "        label = np.round( sitk.GetArrayFromImage(label) ).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "#         seg = sitk.GetArrayFromImage(seg).transpose((2,1,0,3))#tanspose之后才能与sizes匹配\n",
    "        if not image.shape == label.shape:\n",
    "            error_samples_origin.append(sample_name)\n",
    "            print(\"error sample(mismatch shape of image and label):\",sample_name)\n",
    "            continue\n",
    "        \n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        # rescale\n",
    "        ratio = (np.array(newspacing)/np.array(oldspacing)).tolist() \n",
    "        image = transform.rescale(image,ratio,order=1,anti_aliasing=True,preserve_range=True,multichannel=False)\n",
    "        label = np.round(transform.rescale(label,ratio,order=0,anti_aliasing=True,preserve_range=True,multichannel=False)).astype(int)\n",
    "        \n",
    "#         seg = transform.rescale(seg,ratio,order=1,preserve_range=True,multichannel=True)\n",
    "#         sizes = seg.GetSize()#resample后seg的size\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "        print(\"image shape:\",image.shape,\"label shape:\",label.shape)\n",
    "                \n",
    "        \n",
    "#         # offset\n",
    "#         image = image[offset[0]:offset[0]+sizes[0],\n",
    "#                       offset[1]:offset[1]+sizes[1],\n",
    "#                       offset[2]:offset[2]+sizes[2]]\n",
    "#         label = label[offset[0]:offset[0]+sizes[0],\n",
    "#                       offset[1]:offset[1]+sizes[1],\n",
    "#                       offset[2]:offset[2]+sizes[2]].astype(np.uint8)\n",
    "        \n",
    "        # 错误病例：标记的尺寸和image尺寸不同，缺少其中一个类别或者多个类别的标记\n",
    "        print(\"np.unique(label):\",np.unique(label))\n",
    "        if not np.unique(label).tolist()==[0,1,2,3]:\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(no dura/SC):\",sample_name)\n",
    "            continue\n",
    "        \n",
    "        #if not np.abs(np.array(image.shape)-np.array(seg.shape[1::])).sum()<=1:\n",
    "        if not image.shape == label.shape:\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(mismatch shape of image and label):\",sample_name)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        ## 调整类别顺序，注意：seg是onehot编码\n",
    "        target_name = ['dura','bone','SC']#目标类别顺序\n",
    "        idx = [label_name.index(name) for name in target_name]\n",
    "        idx = np.array(idx)+1\n",
    "        idx = [0]+idx.tolist()\n",
    "        label = array_replace(label,olds=[0,1,2,3],news=idx)\n",
    "        \n",
    "        # 合并骨头到背景中\n",
    "        label[label==2] = 0\n",
    "        label[label==3] = 2\n",
    "        \n",
    "        print(\"uncut image.shape:\",image.shape,\"uncut label.shape:\",label.shape)\n",
    "        assert np.unique(label).tolist()==[0,1,2], print('pixel classes are not [0,1,2]') \n",
    "        \n",
    "        # cut\n",
    "        \n",
    "        \n",
    "        minx, maxx = np.min(tempL[0]), np.max(tempL[0])\n",
    "        miny, maxy = np.min(tempL[1]), np.max(tempL[1])\n",
    "        minz, maxz = np.min(tempL[2]), np.max(tempL[2])\n",
    "        w, h, d = label.shape\n",
    "        px = max(output_size[0] - (maxx - minx), 0) // 2\n",
    "        py = max(output_size[1] - (maxy - miny), 0) // 2\n",
    "        minx = max(minx - np.random.randint(10, 20) - px, 0)\n",
    "        maxx = min(maxx + np.random.randint(10, 20) + px, w)\n",
    "        miny = max(miny - np.random.randint(10, 20) - py, 0)\n",
    "        maxy = min(maxy + np.random.randint(10, 20) + py, h)\n",
    "        \n",
    "        image = image[minx:maxx, miny:maxy]\n",
    "        label = label[minx:maxx, miny:maxy]\n",
    "        print(\"cut image.shape:\",image.shape)\n",
    "        print(\"cut label.shape:\",label.shape)\n",
    "        \n",
    "#         f = h5py.File(item.replace(old_replaced, new_replaced), 'w')\n",
    "#         f.create_dataset('image', data=image, compression=\"gzip\")\n",
    "#         f.create_dataset('label', data=label, compression=\"gzip\")\n",
    "#         f.close()\n",
    "    print(\"total number of seg-samples:\", len(listt))\n",
    "    return error_samples, error_samples_origin\n",
    "\n",
    "def covert_h5_unseg(glob_str, old_replaced, new_replaced):\n",
    "    \"\"\"\n",
    "    备注：无标注数据的格式转换\n",
    "    \"\"\"\n",
    "    listt = glob(glob_str)\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "        image = sitk.ReadImage(item)\n",
    "        \n",
    "        # resample\n",
    "        newspacing = [0.3, 0.3, 3.0]\n",
    "        image = resample_image3D(image,newspacing,method='Linear')\n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "        print(\"image shape:\",image.shape)\n",
    "        \n",
    "        f = h5py.File(item.replace(old_replaced, new_replaced), 'w')\n",
    "        f.create_dataset('image', data=image, compression=\"gzip\")\n",
    "        f.close()  \n",
    "    print(\"total number of unseg-samples:\", len(listt))\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # 有标签数据\n",
    "    print('seg dataset:')\n",
    "#     ## 先删除旧文件\n",
    "#     dataset_dir = '../../data/CTM_dataset/Segmented'\n",
    "#     re = os.path.join(dataset_dir,'*/mri_norm2.h5')\n",
    "#     remove_files(re=re)\n",
    "    ## 再生成新文件\n",
    "    glob_str = '../../data/CTM_dataset/Segmented/*/CTM.nrrd'\n",
    "    error_samples,error_samples_origin = covert_h5(glob_str,'CTM.nrrd','mri_norm2.h5')\n",
    "    \n",
    "#     # 无标签数据\n",
    "#     print('unseg dataset:')\n",
    "#     ## 先删除旧文件\n",
    "#     dataset_dir = '../../data/CTM_dataset/unSegmented'\n",
    "#     re = os.path.join(dataset_dir,'*/mri_norm2.h5')\n",
    "#     remove_files(re=re)\n",
    "#     ## 再生成新文件\n",
    "#     glob_str = '../../data/CTM_dataset/unSegmented/*/CTM.nrrd'\n",
    "#     covert_h5_unseg(glob_str,'CTM.nrrd','mri_norm2.h5')\n",
    "#     glob_str = '../../data/CTM_dataset/unSegmented/*/CT-vol.nrrd'\n",
    "#     covert_h5_unseg(glob_str,'CT-vol.nrrd','mri_norm2.h5')      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分&生成*.list文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_split import dataset_split, make_dataset_list\n",
    "# 有标签数据\n",
    "save_dir = '../../data/CTM_dataset'\n",
    "dataset_dir = '../../data/CTM_dataset/Segmented'\n",
    "list_traratioin,list_test = dataset_split(path=dataset_dir,save_dir=save_dir)\n",
    "# 无标签数据\n",
    "dataset_dir = '../../data/CTM_dataset/unSegmented'\n",
    "make_dataset_list(path=dataset_dir,save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#845929 cut前后的shape变化不大"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
