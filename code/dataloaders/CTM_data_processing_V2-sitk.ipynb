{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "血的教训:\n",
    "1. 对mask做插值(rescale,resize),一定且只能在onehot编码上操作\n",
    "2. 不能用skimage,一定要用sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseg dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/212 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1261721 :\n",
      "image shape: (515, 515, 71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/212 [00:02<07:36,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302098 :\n",
      "image shape: (565, 565, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/212 [00:04<07:45,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336587-dingzi :\n",
      "image shape: (555, 555, 71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 3/212 [00:06<07:46,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1532717 :\n",
      "image shape: (468, 468, 82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/212 [00:08<07:37,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1232165 :\n",
      "image shape: (799, 799, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/212 [00:15<11:44,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204336 :\n",
      "image shape: (565, 565, 74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/212 [00:17<10:36,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1330821 :\n",
      "image shape: (512, 512, 82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/212 [00:23<13:43,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1203609 :\n",
      "image shape: (645, 645, 78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/212 [00:27<13:20,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1273842 :\n",
      "image shape: (558, 558, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/212 [00:29<11:52,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610558 :\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import nrrd\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataset_split import remove_files\n",
    "import SimpleITK as sitk\n",
    "from skimage import transform\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "output_size =[128, 128, 64]\n",
    "\n",
    "def resample_image3D(\n",
    "    image3D,\n",
    "    newspacing=[0.3,0.3,3],\n",
    "    newsize=None,\n",
    "    method='Linear',):\n",
    "    \"\"\"做插值\"\"\"\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    if method == 'Linear':\n",
    "        resample.SetInterpolator(sitk.sitkLinear)\n",
    "    elif method == 'Nearest':\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resample.SetOutputDirection(image3D.GetDirection())\n",
    "    resample.SetOutputOrigin(image3D.GetOrigin())\n",
    "    resample.SetOutputSpacing(newspacing)\n",
    "\n",
    "    if not newsize:\n",
    "        newsize = np.round(np.array(image3D.GetSize())*np.abs(image3D.GetSpacing())/np.array(newspacing)).astype('int').tolist()\n",
    "\n",
    "    resample.SetSize(newsize)\n",
    "    # resample.SetDefaultPixelValue(0)\n",
    "\n",
    "    newimage = resample.Execute(image3D)\n",
    "    return newimage\n",
    "\n",
    "def sitk_onehot_transform(image):\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    label_array_onehot = to_categorical(image_array)\n",
    "    image_onehot = sitk.GetImageFromArray(label_array_onehot)\n",
    "    image_onehot.SetOrigin(image.GetOrigin())\n",
    "    image_onehot.SetDirection(image.GetDirection())\n",
    "    image_onehot.SetSpacing(image.GetSpacing())\n",
    "    return image_onehot\n",
    "\n",
    "# 数组替换元素\n",
    "def array_replace(array,olds,news):\n",
    "    # 不适用于onehot\n",
    "    #olds:list of old value\n",
    "    #news:list of new value\n",
    "    olds = np.array(olds)\n",
    "    news = np.array(news)\n",
    "    offset = olds.max()*10\n",
    "    tmps = olds+offset\n",
    "    array += offset\n",
    "    for tmp,new in zip(tmps,news):\n",
    "        array[array==tmp] = new\n",
    "    return array\n",
    "\n",
    "def covert_h5(glob_str, old_replaced, new_replaced):\n",
    "    \"\"\"\n",
    "    备注：不要骨头，骨头合并到背景类别中\n",
    "    \"\"\"\n",
    "    listt = glob(glob_str)\n",
    "    error_samples = []\n",
    "    error_samples_origin = []\n",
    "    stats = pd.DataFrame(columns=['sample_name',\n",
    "                                  'mean_whole', \n",
    "                                  'mean_bg', \n",
    "                                  'mean_dura', \n",
    "                                  'mean_SC', \n",
    "                                  'std_whole',\n",
    "                                  'std_bg',\n",
    "                                  'std_dura',\n",
    "                                  'std_SC',\n",
    "                                  'old_space0','old_space1','old_space2',\n",
    "                                  'new_space0','new_space1','new_space2',\n",
    "                                 ])\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "#         if not sample_name == \"1171704-neck\":#B809338\":#\"\"1352900\":#B809338\":#\"1756747\":#1700637-neck\":\n",
    "#             continue\n",
    "        \n",
    "        # read image\n",
    "        image = sitk.ReadImage(item)\n",
    "        seg = sitk.ReadImage(item.replace(old_replaced, 'Segmentation.seg.nrrd'))\n",
    "        label = sitk.ReadImage(item.replace(old_replaced, 'Segmentation-label.nrrd'))\n",
    "        label_onehot = sitk_onehot_transform(label)\n",
    "        \n",
    "        label_name = [\n",
    "            'bg',\n",
    "            seg.GetMetaData('Segment0_Name'),\n",
    "            seg.GetMetaData('Segment1_Name'),\n",
    "            seg.GetMetaData('Segment2_Name') \n",
    "            ]#人工标注的类别顺序\n",
    "        oldspacing = np.abs(image.GetSpacing())\n",
    "        newspacing = [0.3, 0.3, 3.0]\n",
    "\n",
    "        # resample/rescale( by sitk )\n",
    "        image = resample_image3D(image,newspacing,method='Linear')\n",
    "        label_onehot = resample_image3D(label_onehot,newspacing,method='Nearest')\n",
    "        \n",
    "        # get array\n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "        label_onehot = np.round( sitk.GetArrayFromImage(label_onehot) ).transpose((2,1,0,3))#tanspose之后才能与sizes匹配\n",
    "        label = np.argmax(label_onehot,axis=-1)\n",
    "        plot_slice_sample(image,label,np.nonzero(label)[2].max(),item.replace(old_replaced,'slice_sample_origin.png'))\n",
    "        \n",
    "        \n",
    "        if not image.shape == label_onehot.shape[:-1]:\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(mismatch shape of image and label):\",sample_name)\n",
    "            continue\n",
    "\n",
    "        if not label_onehot.sum(axis=-1).max()==1:\n",
    "            # label onehot encoder可以解决这个问题\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(some pixels in seg are multi-category at the same time):\",sample_name)\n",
    "            continue\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        \n",
    "        # 错误病例：标记的尺寸和image尺寸不同，缺少其中一个类别或者多个类别的标记\n",
    "        if not label_onehot.shape[-1] == 4:\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample(no dura/bone/SC):\",sample_name)\n",
    "            continue \n",
    "        if not (np.unique(label_onehot) == [0, 1]).all():\n",
    "            error_samples.append(sample_name)\n",
    "            print(\"error sample label file error:\",sample_name)   \n",
    "            continue\n",
    "        \n",
    "        ## 调整类别顺序&合并骨头到背景中，注意：是onehot编码\n",
    "        target_name = ['bg','bone','dura','SC']#目标类别顺序\n",
    "        idx = [label_name.index(name) for name in target_name]\n",
    "        assert len(idx)==4,'one or more classes missed'\n",
    "        label_onehot = label_onehot[:,:,:,idx]\n",
    "\n",
    "        ## bone归入背景类\n",
    "        bg = label_onehot[:,:,:,[0,1]].sum(axis=-1)[:,:,:,np.newaxis]\n",
    "        label_onehot = np.concatenate((bg,label_onehot[:,:,:,2:]),axis=-1)\n",
    "        assert (np.unique(label_onehot) == [0, 1]).all(), \"1: pixel class error\"\n",
    "        ## 转化为非onehot编码以便作图\n",
    "        label = np.argmax(label_onehot, axis=-1)\n",
    "        \n",
    "        # cut( random center cut)\n",
    "        tempL = np.nonzero(label)\n",
    "        minx, maxx = np.min(tempL[0]), np.max(tempL[0])\n",
    "        miny, maxy = np.min(tempL[1]), np.max(tempL[1])\n",
    "        minz, maxz = np.min(tempL[2]), np.max(tempL[2])\n",
    "        w, h, d = label.shape\n",
    "        px = max(output_size[0] - (maxx-minx+1), 0) // 2\n",
    "        py = max(output_size[1] - (maxy-miny+1), 0) // 2\n",
    "        #pz = max(output_size[2] - (maxz-minz+1), 0) // 2\n",
    "        minx = max(minx - np.random.randint(10, 20) - px, 0)\n",
    "        maxx = min(maxx + np.random.randint(10, 20) + px, w-1)\n",
    "        miny = max(miny - np.random.randint(10, 20) - py, 0)\n",
    "        maxy = min(maxy + np.random.randint(10, 20) + py, h-1)\n",
    "        #minz = max(minz - np.random.randint(10, 20) - pz, 0)\n",
    "        #maxz = min(maxz + np.random.randint(10, 20) + pz, d)\n",
    "        image = image[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        label = label[minx:maxx+1, miny:maxy+1, minz:maxz+1]\n",
    "        print(\"cut image.shape:\",image.shape, \"cut label.shape:\",label.shape)\n",
    "        plot_slice_sample(image,label,maxz-minz,item.replace(old_replaced,'slice_sample.png'))\n",
    "        \n",
    "        # save files\n",
    "        f = h5py.File(item.replace(old_replaced, new_replaced), 'w')\n",
    "        f.create_dataset('image', data=image, compression=\"gzip\")\n",
    "        f.create_dataset('label', data=label_onehot, compression=\"gzip\")\n",
    "        f.close()\n",
    "    print(\"total number of samples:\", len(listt))\n",
    "    return error_samples, error_samples_origin\n",
    "\n",
    "def plot_slice_sample(image,label,d,fn):\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1, 2, 1)\n",
    "    imgplot = plt.imshow(image[:,:,d].squeeze())\n",
    "    a.set_title('image')\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    a = fig.add_subplot(1, 2, 2)\n",
    "    imgplot = plt.imshow(label[:,:,d].squeeze())\n",
    "    imgplot.set_clim(0.0, 3.0)\n",
    "    a.set_title('label')\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.savefig(fn)\n",
    "    plt.show()\n",
    "    \n",
    "def covert_h5_unseg(glob_str, old_replaced, new_replaced):\n",
    "    \"\"\"\n",
    "    备注：无标注数据的格式转换\n",
    "    \"\"\"\n",
    "    listt = glob(glob_str)\n",
    "    for item in tqdm(listt):\n",
    "        sample_name = item.split('/')[-2]\n",
    "        print(sample_name,':')#win系统改为'\\\\'\n",
    "        image = sitk.ReadImage(item)\n",
    "        \n",
    "        # resample\n",
    "        newspacing = [0.3, 0.3, 3.0]\n",
    "        image = resample_image3D(image,newspacing,method='Linear')\n",
    "        image = sitk.GetArrayFromImage(image).transpose((2,1,0))#tanspose之后才能与sizes匹配\n",
    "        \n",
    "        # 灰度标准化\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = image.astype(np.float32)\n",
    "        print(\"image shape:\",image.shape)\n",
    "        \n",
    "        f = h5py.File(item.replace(old_replaced, new_replaced), 'w')\n",
    "        f.create_dataset('image', data=image, compression=\"gzip\")\n",
    "        f.close()  \n",
    "    print(\"total number of unseg-samples:\", len(listt))\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # 有标签数据\n",
    "#     print('seg dataset:')\n",
    "#     ## 先删除旧文件\n",
    "#     dataset_dir = '../../data/CTM_dataset/Segmented'\n",
    "#     re = os.path.join(dataset_dir,'*/mri_norm2.h5')\n",
    "#     remove_files(re=re)\n",
    "#     ## 再生成新文件\n",
    "#     glob_str = '../../data/CTM_dataset/Segmented/*/CTM.nrrd'\n",
    "#     error_samples,error_samples_origin = covert_h5(glob_str,'CTM.nrrd','mri_norm2.h5')\n",
    "    \n",
    "    # 无标签数据\n",
    "    print('unseg dataset:')\n",
    "    ## 先删除旧文件\n",
    "    dataset_dir = '../../data/CTM_dataset/unSegmented'\n",
    "    re = os.path.join(dataset_dir,'*/mri_norm2.h5')\n",
    "    remove_files(re=re)\n",
    "    ## 再生成新文件\n",
    "    glob_str = '../../data/CTM_dataset/unSegmented/*/CTM.nrrd'\n",
    "    covert_h5_unseg(glob_str,'CTM.nrrd','mri_norm2.h5')\n",
    "    glob_str = '../../data/CTM_dataset/unSegmented/*/CT-vol.nrrd'\n",
    "    covert_h5_unseg(glob_str,'CT-vol.nrrd','mri_norm2.h5')      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分&生成*.list文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_split import dataset_split, make_dataset_list\n",
    "# 有标签数据(划分为两个数据集并生成列表)\n",
    "save_dir = '../../data/CTM_dataset'\n",
    "dataset_dir = '../../data/CTM_dataset/Segmented'\n",
    "list_train_validatioin,list_test = dataset_split(path=dataset_dir,save_dir=save_dir)\n",
    "# 无标签数据(不需要划分,直接生存列表即可)\n",
    "dataset_dir = '../../data/CTM_dataset/unSegmented'\n",
    "make_dataset_list(path=dataset_dir,save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B1709234', '1409022-no SC', 'B1409022', 'B1334915-need revision', '1709234']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
